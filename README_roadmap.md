# üìö Roadmap - Generador de Cuentos Educativos

Fecha de inicio: 2025-04-28

Este roadmap organiza las funcionalidades a implementar y mejoras sugeridas para la aplicaci√≥n. Cada tarea est√° clasificada por prioridad y puede adaptarse seg√∫n feedback o necesidades.

---

## ‚úÖ M√≠nimo producto viable (ya implementado)

- [x] Generaci√≥n de cuentos educativos desde dos URLs de educ.ar
- [x] Scraping de contenidos educativos
- [x] Integraci√≥n con modelo IA Mistral v√≠a Ollama
- [x] Interfaz web en Next.js
- [x] Backend en NestJS
- [x] Base de datos PostgreSQL en Podman

---

## üü° Etapa 1 - Mejoras b√°sicas

- [ ] Exportar cuento generado a PDF
  - [ ] Endpoint `/stories/pdf` que genera y sirve PDF
  - [ ] Bot√≥n "üìÑ Descargar como PDF" en frontend

- [ ] Historial de cuentos generados
  - [ ] Crear tabla `stories` en la base de datos
  - [ ] Guardar t√≠tulo, contenido, urls, fecha
  - [ ] Mostrar historial debajo del generador

- [ ] Validaci√≥n de URLs de educ.ar
  - [ ] Validar formato de URL
  - [ ] Chequear si es alcanzable
  - [ ] Mostrar error √∫til si falla

---

## üü¢ Etapa 2 - Interacci√≥n y personalizaci√≥n

- [ ] Sistema de roles: Docente, Alumno, Invitado
  - [ ] Selecci√≥n manual de rol desde frontend
  - [ ] Ajustar prompt seg√∫n rol

- [ ] Estilos de cuento
  - [ ] Agregar opci√≥n: Hist√≥rico / L√∫dico / Narrativo / Informativo
  - [ ] Ajustar prompt del modelo en base al estilo

- [ ] Continuar cuento (modo Chat)
  - [ ] Guardar historia como contexto
  - [ ] Permitir enviar nuevo input para continuar

---

## üîÑ Extensi√≥n IA - Soporte para OpenAI (Etapa 2)

- [ ] Permitir elegir motor de IA desde el frontend:
  - [ ] `ollama` (por defecto)
  - [ ] `openai`
- [ ] Agregar variable `USE_OPENAI=true` en `.env`
- [ ] Agregar variables necesarias:
  ```env
  OPENAI_API_KEY=sk-xxxxx
  OPENAI_MODEL=gpt-4-turbo
  OPENAI_BASE_URL=https://api.openai.com/v1/chat/completions
  ```
- [ ] En backend, adaptar servicio para elegir el proveedor din√°micamente
- [ ] Mostrar en el historial cu√°l fue el modelo utilizado

---

## üîµ Etapa 3 - Optimizaci√≥n y despliegue

- [ ] `docker-compose.yml` con servicios:
  - [ ] PostgreSQL
  - [ ] Backend (NestJS)
  - [ ] Frontend (Next.js)
  - [ ] Ollama (si posible)

- [ ] Subida del proyecto a GitHub (repos separados o monorepo)
- [ ] Deploy autom√°tico con GitHub Actions o `vercel.json`

---

## üß™ Etapa 4 - Sugerencias avanzadas (a futuro)

- [ ] Clasificaci√≥n autom√°tica del cuento (por √©poca, tema, nivel)
- [ ] Integraci√≥n con IA generativa para ilustraciones (via DALL¬∑E o Stable Diffusion)
- [ ] Exportaci√≥n a EPUB
- [ ] Accesibilidad: lectura con voz (TTS)